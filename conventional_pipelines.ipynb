{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf0572b",
   "metadata": {},
   "source": [
    "# Political Toxicity: Conventional NLP Pipelines\n",
    "Using Apache Spark, the project should be able to take in CSV data from social media posts and classify them accurately as toxic or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bf7d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F, types as T\n",
    "from pyspark.sql import DataFrame\n",
    "spark = SparkSession.builder.appName('Test').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e9248b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, trim, lower, when\n",
    "\"\"\"\n",
    "Maps the column from string values to double values.\n",
    "0.0 in all unknown types or cases\n",
    "\"\"\"\n",
    "def map_toxic_hard(df, col_name=\"toxic_hard\", new_col=\"toxic_score\"):\n",
    "    return df.withColumn(\n",
    "        new_col,\n",
    "        when(trim(lower(col(col_name))) == \"true\", 1)   # string TRUE\n",
    "        .when(trim(lower(col(col_name))) == \"false\", 0) # string FALSE\n",
    "        .otherwise(0)                                   # everything else\n",
    "    )\n",
    "\n",
    "def preprocessing_steps(df: DataFrame) -> DataFrame:\n",
    "    temp = map_toxic_hard(df, \"toxic_hard\", \"toxic_score\")\n",
    "    return temp.select('text','toxic_score') \\\n",
    "        .dropna(subset=['text'])\n",
    "\n",
    "\"\"\"\n",
    "Reads the CSV containing the training data at the given path \n",
    "and returns a spark dataframe.\n",
    "\"\"\"\n",
    "def read_train_data(path:str) -> DataFrame:\n",
    "    seed_df = (\n",
    "        spark.read\n",
    "            .option(\"header\", True)\n",
    "            .option(\"inferSchema\", True)\n",
    "            .option(\"multiline\", True)\n",
    "            .csv(path,sep=',',ignoreLeadingWhiteSpace=True,ignoreTrailingWhiteSpace=True)\n",
    "    )\n",
    "    seed_df = preprocessing_steps(seed_df)\n",
    "    return seed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2569a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"data/train/dataset.csv\"\n",
    "seed_df = read_train_data(train_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4cc5d2",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15806555",
   "metadata": {},
   "source": [
    "For all the tweets we need to remove all tokens that are not useful to the analysis. Then we need to create simple lists of relevant tokens for the unsupervised BERT model to identify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3a66cf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- toxic_score: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "639e324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we need\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.ml.feature import HashingTF\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "#from pyspark.ml import Transformer\n",
    "#from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71747329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline builder\n",
    "\n",
    "# ETL\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol='cleaned_words')\n",
    "\n",
    "# Hash/Vectorize\n",
    "hashingTF = HashingTF(inputCol=remover.getOutputCol(), outputCol='features')\n",
    "\n",
    "# Regression Estimation\n",
    "lr = LogisticRegression(featuresCol='features',labelCol='toxic_score',\n",
    "        maxIter=10, regParam=0.001)\n",
    "\n",
    "# Pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a4782aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA T500\n"
     ]
    }
   ],
   "source": [
    "# Check whether the GPU is open\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ddaaadb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineModel_a60514c2f9fd"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" DEBUG\n",
    "# Print out all parameters for this stage\n",
    "print(\"LogisticRegression parameters:\")\n",
    "print(lr.explainParams())\n",
    "# If you want to check just the labelCol and featuresCol:\n",
    "print(\"Label column:\", lr.getLabelCol())\n",
    "print(\"Features column:\", lr.getFeaturesCol())\n",
    "\"\"\"\n",
    "# Now fit only on the required columns\n",
    "model = pipeline.fit(seed_df)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472527d7",
   "metadata": {},
   "source": [
    "## Predict on Test Data\n",
    "This will load a small test subset and confirm our predictions are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "64e3a891",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"data/test/2pt_test.csv\"\n",
    "\n",
    "test_df = (\n",
    "    spark.read\n",
    "         .option(\"header\", True)\n",
    "         .option(\"inferSchema\", True)\n",
    "         .csv(test_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "273fbbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- toxic_score_true: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "da61616c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+------------------------------------------+\n",
      "|toxic_score_true|prediction|probability                               |\n",
      "+----------------+----------+------------------------------------------+\n",
      "|0.0             |0.0       |[0.9985773268381002,0.0014226731618998123]|\n",
      "|1.0             |1.0       |[9.038140940731217E-5,0.9999096185905927] |\n",
      "+----------------+----------+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test_df)\n",
    "predictions.select('toxic_score_true','prediction','probability').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca5093",
   "metadata": {},
   "source": [
    "## Split Validation\n",
    "Repeat the pipeline building and analysis through split validation to demonstrate the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f3c5ddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "SEED = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "16579c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol='cleaned_words')\n",
    "hashingTF = HashingTF(inputCol=remover.getOutputCol(), outputCol='features')\n",
    "lr = LogisticRegression(featuresCol='features',labelCol='toxic_score',\n",
    "        maxIter=10, regParam=0.001)\n",
    "pipeline = Pipeline(stages=[tokenizer,remover,hashingTF,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "10b8e720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------------------------------+----------+\n",
      "|toxic_score_true|probability                              |prediction|\n",
      "+----------------+-----------------------------------------+----------+\n",
      "|0.0             |[0.8884556385439323,0.11154436145606772] |0.0       |\n",
      "|1.0             |[0.031650691973346586,0.9683493080266534]|1.0       |\n",
      "+----------------+-----------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid = ParamGridBuilder().addGrid(lr.maxIter, [0, 1]).build()\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='toxic_score')\n",
    "tvs = TrainValidationSplit(\n",
    "    estimator=pipeline,parallelism=10,\n",
    "    seed=SEED,\n",
    "    evaluator=evaluator,\n",
    "    estimatorParamMaps=grid)\n",
    "train_df = read_train_data(train_data_path)\n",
    "\n",
    "model = tvs.fit(train_df)\n",
    "model.bestModel.transform(dataset=test_df)\\\n",
    "    .select('toxic_score_true','probability','prediction')\\\n",
    "    .show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b6f6d82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.6995571644466337]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.validationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a5f43e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
